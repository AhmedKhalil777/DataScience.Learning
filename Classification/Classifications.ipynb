{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WHAT IS CLASSIFICATION\n",
    "> Classification is a __data analysis__ task where a model is constructed to predict class labels (categories)\n",
    "\n",
    "## Motivation\n",
    "- Prediction\n",
    "    - In a bank loan => Safe or Risky\n",
    "    - Which treatment is better for patient, __“treatmentX”__ or __“treatmentY”__ ?\n",
    "\n",
    "## Steps:\n",
    "- Learning (training Step):\n",
    "- Classification Step:\n",
    "\n",
    "### Learning Step : => construct classification model\n",
    "- Build classifier for a predetermined set of classes\n",
    "- Learn from a training dataset (data tuples + their associated classes) → Supervised\n",
    "Learning\n",
    "\n",
    "### Classification Step: \n",
    "- model is used to predict class labels for given data (test set)\n",
    "\n",
    "\n",
    "## Let's Code Something\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from pandas import read_csv\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's getting The Iris dataset from My GitHub Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([['Id', 'SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm',\n        'PetalWidthCm', 'Species'],\n       ['1', '5.1', '3.5', '1.4', '0.2', 'Iris-setosa'],\n       ['2', '4.9', '3.0', '1.4', '0.2', 'Iris-setosa'],\n       ['3', '4.7', '3.2', '1.3', '0.2', 'Iris-setosa'],\n       ['4', '4.6', '3.1', '1.5', '0.2', 'Iris-setosa']], dtype=object)"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "url = 'https://media.githubusercontent.com/media/AhmedKhalil777/DataScience.Learning/master/Datasets/Iris.csv'\n",
    "dataframe = read_csv(url, header=None)\n",
    "data = dataframe.values\n",
    "data[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- So What we need, to create a rule or model to predict `Species`\n",
    "- Let's Extract the data without Species and the Species in other column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Shape: (151, 5), (151,)\n"
    }
   ],
   "source": [
    "X, Y = data[:, :-1], data[:, -1]\n",
    "print('Shape: %s, %s' % (X.shape,Y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Without Species\n[['Id' 'SepalLengthCm' 'SepalWidthCm' 'PetalLengthCm' 'PetalWidthCm']\n ['1' '5.1' '3.5' '1.4' '0.2']\n ['2' '4.9' '3.0' '1.4' '0.2']\n ['3' '4.7' '3.2' '1.3' '0.2']\n ['4' '4.6' '3.1' '1.5' '0.2']] \n\n With Species \n['Species' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa']\n"
    }
   ],
   "source": [
    "print(f'Without Species\\n{X[:5]} \\n\\n With Species \\n{Y[:5]}')\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We need to prepare the dataset it's arrays of `str` why it can't be `float64`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[1:].astype('float64')\n",
    "Y = LabelEncoder().fit_transform(Y[1:].astype('str'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[1. , 5.1, 3.5, 1.4, 0.2],\n       [2. , 4.9, 3. , 1.4, 0.2],\n       [3. , 4.7, 3.2, 1.3, 0.2],\n       [4. , 4.6, 3.1, 1.5, 0.2],\n       [5. , 5. , 3.6, 1.4, 0.2]])"
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "X[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]\n"
    }
   ],
   "source": [
    "print(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# evaluate naive\n",
    "\n",
    "> DummyClassifier is a classifier that makes predictions using simple rules.\n",
    "\n",
    "- This classifier is useful as a simple baseline to compare with other (real) classifiers. Do not use it for real problems.\n",
    "- Have 3 Params \n",
    "    - strategy: `str` , default=”stratified” \n",
    "        - “stratified”: generates predictions by respecting the training set’s class distribution.\n",
    "\n",
    "        - “most_frequent”: always predicts the most frequent label in the training set.\n",
    "\n",
    "        - “prior”: always predicts the class that maximizes the class prior (like “most_frequent”) and predict_proba returns the class prior.\n",
    "\n",
    "        - “uniform”: generates predictions uniformly at random.\n",
    "\n",
    "        - “constant”: always predicts a constant label that is provided by the user. This is useful for metrics that evaluate a non-majority class\n",
    "\n",
    "## We Use the most_frequent classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive = DummyClassifier(strategy='most_frequent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Baseline: 0.333 (0.000)\n"
    }
   ],
   "source": [
    "n_scores = cross_val_score(naive, X, Y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "print('Baseline: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([0.33333333, 0.33333333, 0.33333333, 0.33333333, 0.33333333,\n       0.33333333, 0.33333333, 0.33333333, 0.33333333, 0.33333333,\n       0.33333333, 0.33333333, 0.33333333, 0.33333333, 0.33333333,\n       0.33333333, 0.33333333, 0.33333333, 0.33333333, 0.33333333,\n       0.33333333, 0.33333333, 0.33333333, 0.33333333, 0.33333333,\n       0.33333333, 0.33333333, 0.33333333, 0.33333333, 0.33333333])"
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Good: 1.000 (0.000)\n"
    }
   ],
   "source": [
    "model = LinearDiscriminantAnalysis()\n",
    "steps = [('p',PowerTransformer()), ('m',model)]\n",
    "pipeline = Pipeline(steps=steps)\n",
    "m_scores = cross_val_score(pipeline, X, Y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "print('Good: %.3f (%.3f)' % (mean(m_scores), std(m_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}